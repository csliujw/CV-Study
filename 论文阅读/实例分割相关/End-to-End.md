# 汇报

- 第一步
    - 介绍传统的两步走的目标检测方法，Mask R-CNN。 
        - 需要定义大量的proposals，anchors或window centers。
        - 这里的很多设计涉及到先验知识。（常识：举例 anchors大小的选择）
        - 这些proposals anchors可能会有很多重叠的部分。
    - 对比介绍`DERT`网络，于Mask R-CNN相比，DERT的优势在哪里。
        - 结构更简单，没有proposals anchors 和 window centers等。直接预测需要检测的目标对象的集合。
        - DERT直接预测最终的目标集合，通过CNN+transformer结构。
        - 在训练期间，用二分图匹配算法对某个对象进行唯一的预测。每匹配到的则归类为空对象（背景）
- 第二步，介绍dert网络的思想
    - 将目标检测问题视为直接预测一个集合。集合中的值就是需要检测的那些对象。
    - 采用流行的基于transformers encoder-decoder结构。
        - transformer的self-attention机制明确的对序列中元素之间的所有成对交互（pairwise interactions 成对关系）进行建模，使得这些架构特别适合有特定约束的集合预测（）。
    - DERT一次预测所有物体，并且用一个集合损失函数进行端到端的训练，该函数在预测物体和ground truth之间进行二分匹配
    - 简化了检测的过程，丢弃了spatial anchors or non-maximal suppression。
    - 与先前的直接预测集合的工作相比，DETR的主要特点是 二分图匹配损失 和 并行的transformers解码。先前的工作主要是用RNNs进行autoregressive decoding。【我们的匹配损失函数唯一地将预测分配给一个地面真实对象，并且对于预测对象的排列是不变的，因此我们可以并行发射它们。】
    - 用DETR做了一个全景分割的Demo。（大佬就是强）
- 第三步，相关工作
    - 我们的工作建立在先前的集合领域上：集合预测的二分匹配损失；encoder-decoder architectures based on the transformer；并行解码和对象检测方法
    - 先前领域一：集合预测
        - 没有规范的深度学习模型可以直接预测集合。
        - 基本的集合预测任务是多标签分类，其基线方法“一对多”不适用于注入在元素之间存在底层结构检测等问题。这些任务的第一个困难是避免近似重复。大多数当前的检测器使用后处理，例如非最大抑制来解决这个问题，但是直接集预测不需要后处理。他们需要全局推理方案来模拟所有预测元素之间的相互作用，以避免冗余。对于恒定大小的集合预测，密集的全连通网络[9]是足够的，但代价很高。一般的方法是使用自回归序列模型，如递归神经网络（RNN，循环神经网络，无法并行？计算效率？）在所有情况下，损失函数应该通过预测的排列保持不变。通常的解决方案是基于匈牙利算法[20]设计一个损失，以找到基础事实和预测之间的二分匹配。这加强了排列不变性，并保证每个目标元素都有唯一的匹配。我们遵循双方匹配损失方法。然而，与大多数以前的工作相反，我们远离自回归模型（autoregressive model），使用具有并行解码的变压器，这将在下面描述。
    - 先前领域二：并行解码的transformers
        - 
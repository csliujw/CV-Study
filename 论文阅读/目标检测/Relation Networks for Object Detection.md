# Relation Networks for Object Detection

CVPR 2018

# Abstract

尽管人们多年来一直认为，对物体之间的关系进行建模将有助于物体识别，但没有证据表明这一想法在深度学习时代行得通。所有最先进的对象检测系统仍然依赖于单独识别对象实例，而不是在学习过程中利用它们的关系。

本文提出了一个对象关系模型。<span style="color:green">它通过一组对象的外观特征（appearance feature）和几何（geometry）之间的交互来同时处理这些对象</span>，从而允许对它们的关系进行建模。它重量轻，位置合适。它不需要额外的监管，易于嵌入现有网络。在现代目标检测流水线中，它在改进目标识别和重复消除步骤方面是有效的。验证了在基于CNN的检测中建模对象关系的有效性。它产生了第一个完全端到端的物体检测器。代码可从以下网址获得：

- <a href="https://github.com/msracver/Deformable-ConvNets">官方代码地址</a>
- <a href="https://github.com/heefe92/Relation_Networks-pytorch">pytorch实现</a>

# Introduction

近年来，使用深度卷积神经网络(CNNs)的目标检测取得了重大进展。最先进的目标检测方法大多遵循基于区域的。给定一组稀疏的region proposals，分别对每个建议执行对象分类和包围盒回归。然后应用启发式和手工制作的后处理步骤，非最大抑制(NMS)，以消除重复检测。

多年来，视觉社区已经很好地认识到，上下文信息或对象之间的关系有助于对象识别。这样的作品大多是在深度学习盛行之前。在深度学习时代，利用对象关系进行检测学习没有显著的进展。大多数方法仍然侧重于分别识别对象。

一个原因是对象-对象关系很难建模。这些对象位于不同类别、不同比例的任意图像位置，并且它们的数量在不同图像之间可能有所不同。现代基于CNN的方法大多具有简单规则的网络结构。目前还不清楚如何适应现有方法中的上述不规则性。

我们的方法是由自然语言处理领域中注意力模块的成功所推动的。注意模块可以通过聚集来自一组元素(例如，源句子中的所有单词)的信息(或特征)来影响单个元素(例如，机器翻译中的目标句子中的单词)。由任务目标驱动，自动学习聚合权重（aggregation weights）。<span style="color:green">注意力模块可以对元素之间的依赖性进行建模，而无需对它们的位置和特征分布做过多的假设。</span>最近，注意力模块已经成功地应用于视觉问题，例如图像字幕（ image captioning）。

在这项工作中，我们首次提出了一个适用于目标检测的注意模块。它建立在一个基本的注意力模块上。一个明显的区别是，原始元素是对象，而不是单词。这些物体具有2D空间排列和比例/纵横比的变化。它们的位置，或者一般意义上的几何特征，比1D句子中的位置这个词起着更加复杂和重要的作用。<span style="color:green">因此，所提出的模块将原来的注意力权重扩展为两个分量: 原来的权重和新的几何权重。后者对对象之间的空间关系建模，并且只考虑它们之间的相对几何形状，使得模块平移不变，这是对象识别的理想特性。新的几何权重在我们的实验中证明很重要。</span>

该模块称为对象关系模块。它与注意力模块有着相同的优势。它采用可变数量的输入，并行运行（速度快），<span style="color:green">完全可微，并且是原地运行(输入和输出之间没有维度变化)</span>。因此，它作为一个基本的构建模块，可以灵活地用于任何体系结构。<span style="color:red">【可作为一个基本构建模块，灵活运用于任何体系】</span>

具体来说，它被应用于几个最先进的目标检测框架，并显示出一致的改进。如图1所示，它用于改进实例识别步骤和学习重复删除步骤(详见第4.1节)。对于对象检测，关系模块支持所有对象的联合推理，并提高识别精度(第4.2节)。为了消除重复，<span style="color:green">传统的NMS方法被一个轻量级的关系网络(第4.3节)所取代和改进，产生了第一个端到端的对象检测器(第4.4节)。</span>

<img src="../../pics\CV\ISG\Relation Networks for Object Detection\image-20210524175326416.png">

原则上，我们的方法与大多数基于CNN的目标检测方法有着根本的不同，是对它们的补充。<span style="color:green">它利用了一个新的维度: 一组对象被同时处理、推理和相互影响，而不是单独识别。</span>

对象关系模块是通用的，不限于对象检测。可以用于：如实例分割、动作识别、对象关系检测、标题、VQA等。

# Related Works

## Object relation in post-processing

大多数先前的工作使用对象关系作为后处理步骤。通过考虑对象关系，对检测到的对象重新评分。<span style="color:green">例如，DPM使用`共现`来细化对象分数，共现表示两个对象类在同一图像中存在的可能性。</span>随后的方法通过考虑额外的位置和大小，尝试更复杂的关系模型。关于更详细的调查，我们请读者参考<a href="">文献18</a>。这些方法在前深度学习时代取得了一定的成功，但在深度学习时代并不有效。<span style="color:green">一个可能的原因是深层转换网络通过大的感受野隐含地整合了上下文信息。</span>

## Sequential relation modeling

顺序关系建模

最近的几个工作使用LSTM和SMN（空间记忆网络）来建模对象关系。在检测过程中，较早检测到的对象用于帮助查找下一个对象（顺序执行的）。更重要的是，它们没有显示出改进SOTA的对象检测方法的证据（这些方法是简单的前馈网络simple FFN）。

<span style="color:green">相比之下，我们的方法对于多个对象是并行的。它自然适合并改进了现代物体探测器。</span>

## Human centered scenarios

相当多的作品关注human-object的关系。它们通常需要额外的关系注释，比如人类行为。相比之下，我们的方法对于object-object关系是通用的，不需要额外的监督。

## Duplicate removal

尽管使用深度学习的目标检测取得了显著的进步，但完成这一任务的最有效的方法仍然是greedy和hand-crafted的非极大抑制(NMS)及其soft version。<span style="color:green">这个任务自然需要关系建模。例如，NMS使用边界框和分数之间的简单关系。</span>

最近，GossipNet试图通过将一组对象作为一个整体进行处理来学习重复删除，因此与我们有着相似的精神。然而，它的网络是专门为任务设计的，非常复杂(深度>80)。其精度与NMS相当，但计算成本很高。虽然原则上允许端到端学习，但没有实验证据。

相比之下，我们的关系模块简单、通用，并且作为一个应用程序应用于重复删除。我们的去重网络简单得多，计算开销小，超过了SoftNMS。更重要的是，我们首次证明了端到端的对象检测学习是可行和有效的。

## Attention modules in NLP and physical system modeling
注意力模块最近已成功应用于自然语言处理领域和物理系统建模。注意力模块可以很好地捕捉这些问题中的长期依赖性。在自然语言处理中，最近的趋势是用注意力模型代替递归神经网络，实现并行化实现和更有效的学习。

我们的方法就是受这些作品的启发。我们将注意力建模扩展到目标检测这一重要问题。对于建模视觉对象关系，它们的位置，或者一般意义上的几何特征，起着复杂而重要的作用。<span style="color:green">因此，所提出的模块引入了新的几何权重来捕捉对象之间的空间关系。新的几何权重是平移不变的，这是可视化建模的一个重要特性。</span>

# Object Relation Module

<img src="..\..\pics\CV\ISG\Relation Networks for Object Detection\image-20210524201753975.png">

我们首先回顾一个基本的注意力模块，叫做<span style="color:green">“缩放点积注意力”（缩放点积可以解决尺度归一化的问题）</span>。输入由维度$d_k$的查询和键以及维度$d_v$的值组成。在查询和所有关键字之间执行点积，以获得它们的相似性。应用`softmax`函数来获得值的权重。给定一个查询q，所有keys (打包成矩阵K) 和 value(打包成V)，输出值是输入值的加权平均值：
$$
v^{out} = softmax(\frac{qK^t}{\sqrt{d_k}})V-----(1)
$$
我们现在描述对象关系计算。让一个物体由它的几何特征$f_G$和外观特征$f_A$组成。在这项工作中，$f_G$只是一个简单的4维对象边界框，并决定任务（Section 4.2 and 4.3）

<span style="color:green">给定N个对象的输入集合${ (f^n_A, f^n_G) }^N_{n=1}$,整个对象集合相对于第n个对象的关系特征$f_R(n)$计算如下：</span>
$$
f_R(n) = \sum_{m}w^{mn}*(W_V*f^m_A)   -----(2)
$$
输出是来自其他对象的外观特征的加权和，由$W_V$线性变换(对应于等式中的值V (1))。关系权重$w_{mn}$表示来自其他物体的影响。其中$w_{mn}$的计算如下：
$$
w^{mn} = \frac{w_{G}^{mn}*exp(w_{A}^{mn})}{\sum_{k}w^{kn}_{G}*exp(w^{kn}_A)}----- (3)
$$
Appearance weight $w^{mn}_A$的计算类似于公式一的缩放点积。
$$
w^{mn}_{A} = \frac{dot(W_Kf^m_A, W_Qf^n_A)}{\sqrt{d_k}}
$$
$W_k$和$W_Q$矩阵扮演着等式1中的K和Q的角色。

他们将原始特征$f^m_A$和$f^n_A$投影到子空间中，以测量它们的匹配程度。投影后的特征尺寸为$d_k$。

几何权重计算如下：
$$
w^{mn}_G = max \{ 0, W_G* \varepsilon_G(f^m_G,f^n_G) \} -----(5)
$$

----

有两个步骤。

- 首先，将两个对象的几何特征嵌入到$ \varepsilon_G$这个高维表示中。为了使其对平移和比例变换不变，使用了四维相对几何特征。四维相对几何特征：$(log(\frac{|x_m-x_n|}{w_m}),log(\frac{|y_m-y_n|}{h_m}),log(\frac{w_n}{w_m}),log(\frac{h_n}{h_m}))$，这种四维特征通过[56]中的方法嵌入到高维表示中，该方法计算不同波长的余弦和正弦函数。嵌入后的特征维数为$d_g$。
- 第二，嵌入特征由$W_G$转为一标量权重并被修剪为0，acting as a ReLU non-
    linearity。零修剪操作仅限制某些几何关系的对象之间的关系。

---

因为使用了几何权重（等式5）和注意力权重（等式3）使得我们的方法与基本的注意力（等式1）不同。

